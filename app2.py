
# app.py
# -------------------------------------------------------------------
# Streamlit : Comparaison Stock (Total livr√©) vs Quantit√© Command√©e (PO)
# - Normalisation CSV POs (s√©parateurs ; , \t |)
# - S√©lection de feuille Excel (PO & Stock)
# - Matching SAP Name (Stock) ~ Description (PO)
# - Orphelins + meilleur match (affiche PO description + PO Item Code)
# - Background image + overlay + ALERTES ROUGES + D√âTAILS (journal anomalies)
# -------------------------------------------------------------------

import io
import re
import unicodedata
from datetime import datetime

import numpy as np
import pandas as pd
import streamlit as st
from difflib import SequenceMatcher
import base64
from pathlib import Path

st.set_page_config(page_title="Comparaison Stock vs Commandes", layout="wide")

# =========================
# >>> THEME / BACKGROUND <<<
# =========================
def apply_background(image_path: str, overlay_rgba="rgba(255,255,255,0.85)"):
    """
    Applique une image de fond + un overlay translucide pour lire le contenu.
    Place simplement l'image (PNG/JPG) dans le m√™me dossier que app.py.
    """
    try:
        img_path = Path(image_path)
        if not img_path.exists():
            st.warning(f"Image de background introuvable : {image_path}. V√©rifie le nom/fichier.")
            return
        b64 = base64.b64encode(img_path.read_bytes()).decode()
        st.markdown(
            f"""
            <style>
            /* Fond principal de l'app */
            .stApp {{
                background: url("data:image/{img_path.suffix[1:]};base64,{b64}") no-repeat center center fixed;
                background-size: cover;
            }}
            /* Overlay lisible sur le contenu principal */
            .stApp .block-container {{
                background: {overlay_rgba};
                border-radius: 14px;
                padding: 1.2rem 1.6rem;
            }}
            /* Sidebar lisible */
            [data-testid="stSidebar"] {{
                background: {overlay_rgba};
            }}
            /* Petits badges style chips */
            .badge {{
                display:inline-block; padding:0.15rem 0.5rem; border-radius:999px; font-weight:600; font-size:0.85rem;
            }}
            .badge-red  {{ background:#ffe5e5; color:#b00020; border:1px solid #ffb3b3; }}
            .badge-green{{ background:#e7f8ed; color:#0b6b2a; border:1px solid #b3e6c5; }}
            .badge-amber{{ background:#fff5e6; color:#8a4b00; border:1px solid #ffd9a6; }}

            /* Table: rendre la colonne √âcart plus visible */
            td[data-column="√âcart = Stock - Command√©"] {{
                font-weight: 700;
            }}
            </style>
            """,
            unsafe_allow_html=True
        )
    except Exception as e:
        st.warning(f"Impossible d'appliquer le background: {e}")

# üëâ Mets ici le nom exact de ton image
apply_background("image_supply_chain_1.png", overlay_rgba="rgba(255,255,255,0.88)")

# =========================
# Helpers g√©n√©raux (chargement/normalisation)
# =========================
def normalize_colnames(cols):
    return [re.sub(r"\s+", " ", str(c)).strip() for c in cols]

def detect_delimiter(sample_text: str):
    candidates = [';', ',', '\t', '|']
    counts = {sep: sample_text.count(sep) for sep in candidates}
    best = max(counts, key=counts.get)
    return best if counts[best] > 0 else None

def read_csv_safely(uploaded_file) -> pd.DataFrame:
    """Lit un CSV en essayant encodages + s√©parateurs; normalise si une seule colonne avec ';'."""
    if uploaded_file is None:
        return None
    raw = uploaded_file.getvalue()
    # encodages courants
    text = None
    encoding = "utf-8"
    for enc in ("utf-8-sig", "utf-8", "cp1252", "latin1"):
        try:
            text = raw.decode(enc)
            encoding = enc
            break
        except Exception:
            continue
    if text is None:
        text = raw.decode("utf-8", errors="ignore")

    sep = detect_delimiter(text)
    df = None
    try:
        df = pd.read_csv(io.StringIO(text), sep=sep, encoding=encoding, engine="python")
    except Exception:
        for s in (None, ';', ',', '\t', '|'):
            try:
                df = pd.read_csv(io.StringIO(text), sep=s, encoding=encoding, engine="python")
                break
            except Exception:
                continue

    # Si une seule colonne et pr√©sence de ';' -> re-split
    if df is not None and df.shape[1] == 1:
        col = df.columns[0]
        if (';' in col) or df.iloc[:, 0].astype(str).str.contains(';').any():
            split_df = df.iloc[:, 0].astype(str).str.split(';', expand=True)
            first_row = split_df.iloc[0]
            looks_like_header = any(h.lower() in ["item code", "qty", "created_at", "description"]
                                    for h in first_row.astype(str).str.lower())
            if looks_like_header:
                split_df.columns = [re.sub(r"\s+", " ", str(x)).strip() for x in first_row]
                split_df = split_df.iloc[1:].reset_index(drop=True)
            df = split_df

    if df is None:
        return None

    df.columns = normalize_colnames(df.columns)
    # garder Item Code en texte
    for c in df.columns:
        if "item" in c.lower() and "code" in c.lower():
            df[c] = df[c].astype(str).str.strip()
    return df

def read_excel_with_sheet_selector(uploaded_file, key_prefix: str):
    """Propose la s√©lection de feuille dans la sidebar et retourne le DF de la feuille choisie."""
    if uploaded_file is None:
        return None
    raw = uploaded_file.getvalue()
    xls = pd.ExcelFile(io.BytesIO(raw), engine="openpyxl")
    sheet_names = xls.sheet_names
    st.sidebar.caption(f"üìë Feuilles d√©tect√©es ({key_prefix})")
    sheet = st.sidebar.selectbox(
        f"S√©lectionne la feuille pour {key_prefix}",
        options=sheet_names,
        index=0,
        key=f"{key_prefix}_sheet_select"
    )
    df = pd.read_excel(io.BytesIO(raw), sheet_name=sheet, engine="openpyxl")
    df.columns = normalize_colnames(df.columns)
    for c in df.columns:
        if "item" in c.lower() and "code" in c.lower():
            df[c] = df[c].astype(str).str.strip()
    return df

def load_any_table(uploaded_file, key_prefix: str):
    """Charge CSV ou Excel + s√©lection de feuille pour Excel, normalisation CSV."""
    if uploaded_file is None:
        return None
    name = uploaded_file.name.lower()
    if name.endswith(".csv"):
        return read_csv_safely(uploaded_file)
    elif name.endswith(".xlsx") or name.endswith(".xls"):
        return read_excel_with_sheet_selector(uploaded_file, key_prefix=key_prefix)
    else:
        try:
            return read_csv_safely(uploaded_file)
        except Exception:
            return None

def guess_column(cols, candidates):
    """Devine une colonne via mots-cl√©s ou regex."""
    cols_norm = [c.lower() for c in cols]
    for cand in candidates:
        cand_low = cand.lower()
        for c in cols_norm:
            if cand_low in c:
                return cols[cols_norm.index(c)]
    for cand in candidates:
        if cand.startswith("^") or cand.endswith("$"):
            pat = re.compile(cand, re.I)
            for i, c in enumerate(cols):
                if re.search(pat, c):
                    return cols[i]
    return None

def coerce_numeric(series):
    """Convertit vers num√©rique en tol√©rant %, espaces, virgules FR."""
    s = series.astype(str).str.replace("%", "", regex=False)
    s = s.str.replace("\u202f", "", regex=False)  # espace fine
    s = s.str.replace(" ", "", regex=False)
    s = s.str.replace(",", ".", regex=False)      # d√©cimales FR
    return pd.to_numeric(s, errors="coerce")

def strip_accents(text: str) -> str:
    """Supprime les accents pour une comparaison robuste."""
    try:
        text = unicodedata.normalize('NFKD', text)
        text = text.encode('ASCII', 'ignore').decode('utf-8')
        return text
    except Exception:
        return text

def clean_text(t: str) -> str:
    """Nettoie/normalise texte pour matching."""
    if t is None:
        return ""
    t = str(t).lower()
    t = strip_accents(t)
    t = re.sub(r"[^\w\s\-]", " ", t)
    t = re.sub(r"\s+", " ", t).strip()
    return t

def token_set(text: str):
    return set(clean_text(text).split())

from difflib import SequenceMatcher
def similarity(a: str, b: str):
    """Similarit√© combin√©e: difflib + Jaccard (0.6/0.4)."""
    a_clean, b_clean = clean_text(a), clean_text(b)
    if not a_clean and not b_clean:
        return 0.0
    seq = SequenceMatcher(None, a_clean, b_clean).ratio()
    ta, tb = token_set(a_clean), token_set(b_clean)
    inter = len(ta & tb)
    union = len(ta | tb) if (ta or tb) else 1
    jacc = inter / union
    return 0.6 * seq + 0.4 * jacc

def find_best_match(query_text: str, candidates: pd.Series, top_n=3):
    scores = candidates.fillna("").astype(str).apply(lambda x: similarity(query_text, x))
    top_idx = scores.sort_values(ascending=False).head(top_n).index
    return pd.DataFrame({
        "po_index": top_idx,
        "po_description": candidates.loc[top_idx].values,
        "score": scores.loc[top_idx].values
    })

def to_excel_bytes(df_dict: dict):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        for sheet, df in df_dict.items():
            pd.DataFrame(df).to_excel(writer, index=False, sheet_name=sheet[:31])
    return output.getvalue()

# =========================
# Sidebar: chargement
# =========================
st.sidebar.title("‚öôÔ∏è Param√®tres")

st.sidebar.header("1) Charger les fichiers")
po_file    = st.sidebar.file_uploader("Fichier POs (CSV/XLSX)",   type=["csv", "xlsx", "xls"], key="po_file")
stock_file = st.sidebar.file_uploader("Fichier Stock (CSV/XLSX)", type=["csv", "xlsx", "xls"], key="stock_file")

po_df    = load_any_table(po_file,    key_prefix="PO")
stock_df = load_any_table(stock_file, key_prefix="STOCK")

# =========================
# Titre
# =========================
st.title("üì¶ Comparaison Stock (Total livr√©) vs Quantit√© Command√©e (PO)")

# Aper√ßus
col1, col2 = st.columns(2)
with col1:
    if po_df is not None:
        st.subheader("Aper√ßu POs")
        st.dataframe(po_df.head(25), use_container_width=True)
with col2:
    if stock_df is not None:
        st.subheader("Aper√ßu Stock")
        st.dataframe(stock_df.head(25), use_container_width=True)

if (po_df is None) or (stock_df is None):
    st.info("‚û°Ô∏è Merci d‚Äôuploader **les deux fichiers**. Cette version normalise les CSV et permet la s√©lection de feuille Excel.")
    st.stop()

# =========================
# Mapping des colonnes
# =========================
st.sidebar.header("2) Mapper les colonnes")

# POs
st.sidebar.caption("üü¶ Colonnes POs")
po_item_col = st.sidebar.selectbox(
    "Colonne Item Code (PO)",
    options=po_df.columns,
    index=(po_df.columns.tolist().index(guess_column(po_df.columns, ["item code", "item", "code"]))
           if guess_column(po_df.columns, ["item code", "item", "code"]) in po_df.columns else 0)
)
po_qty_col = st.sidebar.selectbox(
    "Colonne Quantit√© (PO)",
    options=po_df.columns,
    index=(po_df.columns.tolist().index(guess_column(po_df.columns, ["qty", "quantity", "^qte$", "qte"]))
           if guess_column(po_df.columns, ["qty", "quantity", "^qte$", "qte"]) in po_df.columns else 0)
)
po_date_col = st.sidebar.selectbox(
    "Colonne Date PO (facultatif)",
    options=["(aucune)"] + po_df.columns.tolist(),
    index=(po_df.columns.tolist().index(guess_column(po_df.columns, ["created_at", "po date", "date"])) + 1
           if guess_column(po_df.columns, ["created_at", "po date", "date"]) in po_df.columns else 0)
)
po_desc_col = st.sidebar.selectbox(
    "Colonne Description (POs - pour matching)",
    options=["(aucune)"] + po_df.columns.tolist(),
    index=(po_df.columns.tolist().index(guess_column(po_df.columns, ["description", "desc"])) + 1
           if guess_column(po_df.columns, ["description", "desc"]) in po_df.columns else 0)
)

# Stock
st.sidebar.caption("üü© Colonnes Stock")
stock_item_col = st.sidebar.selectbox(
    "Colonne Item Code (Stock)",
    options=stock_df.columns,
    index=(stock_df.columns.tolist().index(guess_column(stock_df.columns, ["item code", "item", "code"]))
           if guess_column(stock_df.columns, ["item code", "item", "code"]) in stock_df.columns else 0)
)
stock_qty_col = st.sidebar.selectbox(
    "Colonne Quantit√© Stock (Total livr√© / Stock Qty)",
    options=stock_df.columns,
    index=(stock_df.columns.tolist().index(guess_column(stock_df.columns, ["total livr√©", "stock qty", "total stock", "qty", "quantity"]))
           if guess_column(stock_df.columns, ["total livr√©", "stock qty", "total stock", "qty", "quantity"]) in stock_df.columns else 0)
)
stock_sapname_col = st.sidebar.selectbox(
    "Colonne SAP Name (Stock - pour matching)",
    options=["(aucune)"] + stock_df.columns.tolist(),
    index=(stock_df.columns.tolist().index(guess_column(stock_df.columns, ["sap name", "sap", "designation", "item name"])) + 1
           if guess_column(stock_df.columns, ["sap name", "sap", "designation", "item name"]) in stock_df.columns else 0)
)

# =========================
# Pr√©paration & filtres
# =========================
po_df["_item"] = po_df[po_item_col].astype(str).str.strip()
stock_df["_item"] = stock_df[stock_item_col].astype(str).str.strip()

po_df["_qty"] = coerce_numeric(po_df[po_qty_col])
stock_df["_stock_qty"] = coerce_numeric(stock_df[stock_qty_col])

if po_date_col and po_date_col != "(aucune)":
    po_df["_date"] = pd.to_datetime(po_df[po_date_col], errors="coerce", dayfirst=True)
else:
    po_df["_date"] = pd.NaT

st.sidebar.header("3) Filtres")
alert_threshold = st.sidebar.slider("Seuil Alerte % √©carts n√©gatifs", 0, 100, 20, help="Au-del√†, alerte rouge globale")
if po_df["_date"].notna().any():
    dmin = pd.to_datetime(po_df["_date"].min())
    dmax = pd.to_datetime(po_df["_date"].max())
    date_range = st.sidebar.date_input("Filtrer par date PO", (dmin.date(), dmax.date()))
    if isinstance(date_range, tuple) and len(date_range) == 2:
        start, end = pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1])
        po_df = po_df[(po_df["_date"] >= start) & (po_df["_date"] <= end)]
else:
    st.sidebar.caption("Aucune date valide d√©tect√©e dans les POs.")

item_filter = st.sidebar.text_input("Filtrer par Item Code (contient‚Ä¶)", "")
if item_filter.strip():
    po_df = po_df[po_df["_item"].str.contains(item_filter.strip(), case=False, na=False)]

# =========================
# Agr√©gations principales
# =========================
agg_po = (po_df
          .groupby("_item", dropna=False)
          .agg(
              total_commande=("_qty", "sum"),
              nb_pos=("_qty", "count"),
              derniere_date=("_date", "max"),
              description=(po_desc_col, "last") if (po_desc_col and po_desc_col != "(aucune)") else ("_item", "first")
          )
          .reset_index()
         )

agg_stock = (stock_df
             .groupby("_item", dropna=False)
             .agg(
                 stock_total=("_stock_qty", "sum"),
                 sap_name=(stock_sapname_col, "last") if (stock_sapname_col and stock_sapname_col != "(aucune)") else ("_item", "first")
             )
             .reset_index()
            )

res = agg_po.merge(agg_stock, on="_item", how="outer")
res["total_commande"] = res["total_commande"].fillna(0)
res["stock_total"] = res["stock_total"].fillna(0)

res["ecart_stock_moins_commande"] = res["stock_total"] - res["total_commande"]
res["taux_couverture"] = np.where(res["total_commande"] > 0,
                                  res["stock_total"] / res["total_commande"],
                                  np.nan)

final_cols = {
    "_item": "Item Code",
    "description": "Description (PO)",
    "sap_name": "SAP Name (Stock)",
    "nb_pos": "Nb POs",
    "derniere_date": "Derni√®re date PO",
    "total_commande": "Total command√©",
    "stock_total": "Stock (Total livr√©)",
    "ecart_stock_moins_commande": "√âcart = Stock - Command√©",
    "taux_couverture": "Taux de couverture"
}
res = res.rename(columns=final_cols)
res = res[list(final_cols.values())]

# =========================
# KPIs + ALERTES ROUGES
# =========================
all_items_mask = (res["Total command√©"].fillna(0) + res["Stock (Total livr√©)"].fillna(0)) > 0
nb_total_items = int(all_items_mask.sum())
nb_neg = int((res["√âcart = Stock - Command√©"] < 0).sum())
nb_pos = int((res["√âcart = Stock - Command√©"] > 0).sum())
pct_neg = (nb_neg / nb_total_items * 100) if nb_total_items else 0
pct_pos = (nb_pos / nb_total_items * 100) if nb_total_items else 0

colA, colB, colC, colD = st.columns(4)
with colA:
    st.metric("Total command√© (tous items)", f"{res['Total command√©'].sum():,.0f}")
with colB:
    st.metric("Stock total (tous items)", f"{res['Stock (Total livr√©)'].sum():,.0f}")
with colC:
    st.metric("√âcart global (Stock - Command√©)",
              f"{(res['Stock (Total livr√©)'].sum() - res['Total command√©'].sum()):,.0f}")
with colD:
    st.metric("√âcarts (+ / -)", f"{pct_pos:.1f}% / {pct_neg:.1f}%")

def show_alerts():
    messages = []
    if pct_neg >= alert_threshold:
        messages.append(f"‚ö†Ô∏è {pct_neg:.1f}% des items ont un **√©cart n√©gatif** (stock < command√©).")
    # Orphelins
    _orph = res[(res["Stock (Total livr√©)"] > 0) & (res["Total command√©"] == 0)]
    if len(_orph) > 0:
        messages.append(f"üì¶ **{len(_orph)} item(s) en stock sans PO** (orphelins).")
    # Items inexistants (ni stock ni PO)
    _void = res[(res["Stock (Total livr√©)"] == 0) & (res["Total command√©"] == 0)]
    if len(_void) > 0:
        messages.append(f"‚ÑπÔ∏è {len(_void)} r√©f√©rence(s) sans activit√© (ni stock ni commande) dans la plage filtr√©e.")
    if messages:
        st.error(" / ".join(messages))
    else:
        st.success("Tout est OK ‚úÖ : aucun signal critique sur la p√©riode.")

show_alerts()

# =========================
# D√©tails (table principale)
# =========================
st.markdown("### üßæ D√©tails par Item")
def color_ecart(val):
    try:
        v = float(val)
        if v < 0:  # n√©gatif -> rouge
            return "background-color:#ffefef;color:#b00020;font-weight:700;"
        elif v > 0:  # positif -> vert clair
            return "background-color:#eaffea;color:#0b6b2a;font-weight:700;"
    except:
        pass
    return ""
styled = (res
          .style
          .format({
              "Total command√©": "{:,.0f}",
              "Stock (Total livr√©)": "{:,.0f}",
              "√âcart = Stock - Command√©": "{:,.0f}",
              "Taux de couverture": "{:.2%}"
          })
          .applymap(color_ecart, subset=["√âcart = Stock - Command√©"])
         )
st.dataframe(styled, use_container_width=True, hide_index=True)

# =========================
# Analyse avanc√©e : Orphelins & matching
# =========================
st.markdown("## üîç Analyse avanc√©e : Items en Stock sans PO & correspondances par similarit√©")

st.sidebar.header("4) Param√®tres de matching")
similarity_threshold = st.sidebar.slider("Seuil de similarit√© (0‚Äì1)", 0.0, 1.0, 0.65, 0.05)
top_n_matches = st.sidebar.slider("Top-N correspondances par item", 1, 5, 3)

# Orphans = items avec stock>0 ET total_commande==0
orphans = res[(res["Stock (Total livr√©)"] > 0) & (res["Total command√©"] == 0)].copy()
st.write(f"**Items orphelins d√©tect√©s (stock > 0, aucune commande)** : {len(orphans)}")

# S√©ries POs pour matching
if po_desc_col and po_desc_col != "(aucune)" and po_desc_col in po_df.columns:
    po_desc_clean = po_df[po_desc_col].fillna("").astype(str)
else:
    po_desc_clean = pd.Series(dtype=str)

po_item_series = po_df["_item"].fillna("").astype(str)
po_qty_series  = po_df["_qty"].reset_index(drop=True)

matches_rows = []
if not orphans.empty and not po_desc_clean.empty and (stock_sapname_col and stock_sapname_col != "(aucune)"):
    po_desc_indexed = po_desc_clean.reset_index(drop=False)
    po_desc_indexed.columns = ["po_row_index", "po_description"]
    po_desc_indexed["po_item_code"] = po_item_series.reset_index(drop=True)

    for _, r in orphans.iterrows():
        stock_item   = r["Item Code"]
        stock_name   = r["SAP Name (Stock)"]
        stock_qty    = r["Stock (Total livr√©)"]

        top_df = find_best_match(stock_name, po_desc_indexed["po_description"], top_n=top_n_matches)

        top_df["po_item_code"] = top_df["po_index"].apply(
            lambda i: po_desc_indexed.loc[i, "po_item_code"] if i in po_desc_indexed.index else np.nan
        )
        top_df["po_qty_line"] = top_df["po_index"].apply(
            lambda i: po_qty_series.iloc[i] if i < len(po_qty_series) else np.nan
        )

        top_df["stock_item_code"] = stock_item
        top_df["stock_sap_name"]  = stock_name
        top_df["stock_qty"]       = stock_qty

        top_df = top_df[top_df["score"] >= similarity_threshold]
        if not top_df.empty:
            matches_rows.append(top_df)

if matches_rows:
    matches_df = pd.concat(matches_rows, ignore_index=True)
    matches_df["po_qty_line"] = pd.to_numeric(matches_df["po_qty_line"], errors="coerce")
    agg_matches = (matches_df
                   .groupby(["stock_item_code", "stock_sap_name", "po_description", "po_item_code"], dropna=False)
                   .agg(
                       similarity=("score", "max"),
                       stock_qty=("stock_qty", "first"),
                       total_po_qty_assoc=("po_qty_line", "sum")
                   ).reset_index())
else:
    agg_matches = pd.DataFrame(columns=["stock_item_code", "stock_sap_name", "po_description", "po_item_code", "similarity", "stock_qty", "total_po_qty_assoc"])

st.markdown("### üß© Correspondances propos√©es (SAP Name ~ Description PO)")
if agg_matches.empty:
    st.info("Aucune correspondance propos√©e selon le seuil actuel. Essaie d‚Äôabaisser le seuil de similarit√©.")
else:
    st.dataframe(
        agg_matches.sort_values(["similarity", "stock_qty"], ascending=[False, False]),
        use_container_width=True
    )

# ---- Tableau demand√© : les orphelins + meilleur match (desc + item code PO) ----
if not agg_matches.empty:
    best_matches = (agg_matches.sort_values(["stock_item_code", "similarity"], ascending=[True, False])
                    .groupby("stock_item_code", as_index=False)
                    .first())
    orphans_summary = (orphans[["Item Code", "SAP Name (Stock)", "Stock (Total livr√©)"]]
                       .merge(best_matches.rename(columns={
                           "stock_item_code": "Item Code",
                           "stock_sap_name": "SAP Name (Stock)",
                           "po_description": "PO description correspondante",
                           "po_item_code": "PO Item Code",
                           "similarity": "Similarit√©",
                           "total_po_qty_assoc": "Total Qty PO (assoc.)"
                       }),
                              on=["Item Code", "SAP Name (Stock)"],
                              how="left"))
    orphans_summary["Match trouv√© ?"] = np.where(orphans_summary["PO description correspondante"].notna(), "Oui", "Non")
else:
    orphans_summary = orphans[["Item Code", "SAP Name (Stock)", "Stock (Total livr√©)"]].copy()
    orphans_summary["PO description correspondante"] = np.nan
    orphans_summary["PO Item Code"] = np.nan
    orphans_summary["Similarit√©"] = np.nan
    orphans_summary["Total Qty PO (assoc.)"] = np.nan
    orphans_summary["Match trouv√© ?"] = "Non"

st.markdown("### üìã Orphelins ‚Äî meilleur match (description & Item Code PO)")
st.dataframe(
    orphans_summary.sort_values(["Match trouv√© ?", "Similarit√©"], ascending=[True, False]),
    use_container_width=True
)

# =========================
# D√âTAILS & Journal anomalies
# =========================
with st.expander("‚ÑπÔ∏è D√©tails & contr√¥les qualit√© (clique pour ouvrir)"):
    st.markdown("""
    **Contr√¥les effectu√©s par l'application :**
    - Normalisation POs (CSV √† s√©parateur ; , \\t |) et protection **Item Code** en texte.
    - S√©lection de **feuille Excel** pour Stock/POs.
    - Agr√©gation par **Item Code** : *Total command√©*, *Stock (Total livr√©)*.
    - Calcul **√âcart = Stock - Command√©** et **Taux de couverture**.
    - D√©tection **Orphelins** (stock > 0, aucune commande).
    - Matching par similarit√© **SAP Name** (Stock) ‚Üî **Description** (POs) + r√©cup√©ration **PO Item Code**.
    - Export Excel multi-feuilles : Comparaison, Orphans, Correspondances d√©taill√©es, Orphelins + meilleur match, Synth√®se KPI.
    """)

    st.markdown("**Journal d‚Äôanomalies :**")
    anomalies = {
        "√âcarts n√©gatifs (stock < command√©)": res[res["√âcart = Stock - Command√©"] < 0][["Item Code","Description (PO)","SAP Name (Stock)","Total command√©","Stock (Total livr√©)","√âcart = Stock - Command√©"]],
        "Orphelins (stock > 0, aucune commande)": orphans[["Item Code","SAP Name (Stock)","Stock (Total livr√©)"]],
        "R√©f√©rences sans activit√© (0 stock & 0 PO)": res[(res["Stock (Total livr√©)"] == 0) & (res["Total command√©"] == 0)][["Item Code","Description (PO)","SAP Name (Stock)"]],
    }
    for title, df_ in anomalies.items():
        st.markdown(f"- <span class='badge badge-red'>{title} ‚Äî {len(df_)}</span>", unsafe_allow_html=True)
        if len(df_) > 0:
            st.dataframe(df_, use_container_width=True)

# =========================
# Visualisation (Top √©carts)
# =========================
st.markdown("### üîé Top 20 des √©carts (absolus)")
top = res.assign(abs_ecart=res["√âcart = Stock - Command√©"].abs()).sort_values("abs_ecart", ascending=False).head(20)
chart_data = top[["Item Code", "√âcart = Stock - Command√©"]].set_index("Item Code")
st.bar_chart(chart_data)

# =========================
# Export Excel multi-feuilles
# =========================
st.markdown("### üì• Export")
summary_df = pd.DataFrame({
    "KPI": ["Total command√©", "Stock total", "√âcart global", "% √âcarts positifs", "% √âcarts n√©gatifs",
            "Orphans (Stock sans PO)", "Orphans avec meilleur match"],
    "Valeur": [
        res["Total command√©"].sum(),
        res["Stock (Total livr√©)"].sum(),
        res["Stock (Total livr√©)"].sum() - res["Total command√©"].sum(),
        pct_pos,
        pct_neg,
        len(orphans),
        int(orphans_summary["Match trouv√© ?"].eq("Oui").sum())
    ]
})

excel_bytes = to_excel_bytes({
    "Comparaison": res,
    "Orphans": orphans,
    "Correspondances_d√©taill√©es": agg_matches,
    "Orphans_meilleur_match": orphans_summary,
    "Synthese_KPI": summary_df
})
st.download_button(
    label="T√©l√©charger l‚Äôanalyse (Excel)",
    data=excel_bytes,
    file_name=f"analyse_stock_vs_pos_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)

st.caption("Astuce : ajuste le **seuil de similarit√©** et le **seuil d‚Äôalerte** pour ton contexte.")
